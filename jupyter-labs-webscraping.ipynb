{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\">\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Space X  Falcon 9 First Stage Landing Prediction**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web scraping Falcon 9 and Falcon Heavy Launches Records from Wikipedia\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **40** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will be performing web scraping to collect Falcon 9 historical launch records from a Wikipedia page titled `List of Falcon 9 and Falcon Heavy launches`\n",
    "\n",
    "https://en.wikipedia.org/wiki/List_of_Falcon_9_and_Falcon_Heavy_launches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/labs/module_1_L2/images/Falcon9_rocket_family.svg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Falcon 9 first stage will land successfully\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DS0701EN-SkillsNetwork/api/Images/landing_1.gif)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several examples of an unsuccessful landing are shown here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DS0701EN-SkillsNetwork/api/Images/crash.gif)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More specifically, the launch records are stored in a HTML table shown below:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/labs/module_1_L2/images/falcon9-launches-wiki.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Objectives\n",
    "Web scrap Falcon 9 launch records with `BeautifulSoup`: \n",
    "- Extract a Falcon 9 launch records HTML table from Wikipedia\n",
    "- Parse the table and convert it into a Pandas data frame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's import required packages for this lab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\mywork\\devenv\\anaconda3\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\mywork\\devenv\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: requests in c:\\mywork\\devenv\\anaconda3\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\mywork\\devenv\\anaconda3\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\mywork\\devenv\\anaconda3\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\mywork\\devenv\\anaconda3\\lib\\site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\mywork\\devenv\\anaconda3\\lib\\site-packages (from requests) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install beautifulsoup4\n",
    "!pip3 install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import unicodedata\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we will provide some helper functions for you to process web scraped HTML table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_time(table_cells):\n",
    "    \"\"\"\n",
    "    This function returns the data and time from the HTML  table cell\n",
    "    Input: the  element of a table data cell extracts extra row\n",
    "    \"\"\"\n",
    "    return [data_time.strip() for data_time in list(table_cells.strings)][0:2]\n",
    "\n",
    "def booster_version(table_cells):\n",
    "    \"\"\"\n",
    "    This function returns the booster version from the HTML  table cell \n",
    "    Input: the  element of a table data cell extracts extra row\n",
    "    \"\"\"\n",
    "    out=''.join([booster_version for i,booster_version in enumerate( table_cells.strings) if i%2==0][0:-1])\n",
    "    return out\n",
    "\n",
    "def landing_status(table_cells):\n",
    "    \"\"\"\n",
    "    This function returns the landing status from the HTML table cell \n",
    "    Input: the  element of a table data cell extracts extra row\n",
    "    \"\"\"\n",
    "    out=[i for i in table_cells.strings][0]\n",
    "    return out\n",
    "\n",
    "\n",
    "def get_mass(table_cells):\n",
    "    mass=unicodedata.normalize(\"NFKD\", table_cells.text).strip()\n",
    "    if mass:\n",
    "        mass.find(\"kg\")\n",
    "        new_mass=mass[0:mass.find(\"kg\")+2]\n",
    "    else:\n",
    "        new_mass=0\n",
    "    return new_mass\n",
    "\n",
    "\n",
    "def extract_column_from_header(row):\n",
    "    \"\"\"\n",
    "    This function returns the landing status from the HTML table cell \n",
    "    Input: the  element of a table data cell extracts extra row\n",
    "    \"\"\"\n",
    "    if (row.br):\n",
    "        row.br.extract()\n",
    "    if row.a:\n",
    "        row.a.extract()\n",
    "    if row.sup:\n",
    "        row.sup.extract()\n",
    "        \n",
    "    colunm_name = ' '.join(row.contents)\n",
    "    \n",
    "    # Filter the digit and empty names\n",
    "    if not(colunm_name.strip().isdigit()):\n",
    "        colunm_name = colunm_name.strip()\n",
    "        return colunm_name    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep the lab tasks consistent, you will be asked to scrape the data from a snapshot of the  `List of Falcon 9 and Falcon Heavy launches` Wikipage updated on\n",
    "`9th June 2021`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_url = \"https://en.wikipedia.org/w/index.php?title=List_of_Falcon_9_and_Falcon_Heavy_launches&oldid=1027686922\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, request the HTML page from the above URL and get a `response` object\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK 1: Request the Falcon9 Launch Wiki page from its URL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's perform an HTTP GET method to request the Falcon9 Launch HTML page, as an HTTP response.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use requests.get() method with the provided static_url\n",
    "# assign the response to a object\n",
    "data  = requests.get(static_url).text\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `BeautifulSoup` object from the HTML `response`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use BeautifulSoup() to create a BeautifulSoup object from a response text content\n",
    "soup = BeautifulSoup(data, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the page title to verify if the `BeautifulSoup` object was created properly \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>List of Falcon 9 and Falcon Heavy launches - Wikipedia</title>\n"
     ]
    }
   ],
   "source": [
    "# Use soup.title attribute\n",
    "print(soup.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK 2: Extract all column/variable names from the HTML table header\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to collect all relevant column names from the HTML table header\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to find all tables on the wiki page first. If you need to refresh your memory about `BeautifulSoup`, please check the external reference link towards the end of this lab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the find_all function in the BeautifulSoup object, with element type `table`\n",
    "# Assign the result to a list called `html_tables`\n",
    "html_tables = soup.find_all('table')\n",
    "#print(html_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting from the third table is our target table contains the actual launch records.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's print the third table and check its content\n",
    "first_launch_table = html_tables[2]\n",
    "# print(first_launch_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should able to see the columns names embedded in the table header elements `<th>` as follows:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "<tr>\n",
    "<th scope=\"col\">Flight No.\n",
    "</th>\n",
    "<th scope=\"col\">Date and<br/>time (<a href=\"/wiki/Coordinated_Universal_Time\" title=\"Coordinated Universal Time\">UTC</a>)\n",
    "</th>\n",
    "<th scope=\"col\"><a href=\"/wiki/List_of_Falcon_9_first-stage_boosters\" title=\"List of Falcon 9 first-stage boosters\">Version,<br/>Booster</a> <sup class=\"reference\" id=\"cite_ref-booster_11-0\"><a href=\"#cite_note-booster-11\">[b]</a></sup>\n",
    "</th>\n",
    "<th scope=\"col\">Launch site\n",
    "</th>\n",
    "<th scope=\"col\">Payload<sup class=\"reference\" id=\"cite_ref-Dragon_12-0\"><a href=\"#cite_note-Dragon-12\">[c]</a></sup>\n",
    "</th>\n",
    "<th scope=\"col\">Payload mass\n",
    "</th>\n",
    "<th scope=\"col\">Orbit\n",
    "</th>\n",
    "<th scope=\"col\">Customer\n",
    "</th>\n",
    "<th scope=\"col\">Launch<br/>outcome\n",
    "</th>\n",
    "<th scope=\"col\"><a href=\"/wiki/Falcon_9_first-stage_landing_tests\" title=\"Falcon 9 first-stage landing tests\">Booster<br/>landing</a>\n",
    "</th></tr>\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we just need to iterate through the `<th>` elements and apply the provided `extract_column_from_header()` to extract column name one by one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = []\n",
    "\n",
    "# Apply find_all() function with `th` element on first_launch_table\n",
    "# Iterate each th element and apply the provided extract_column_from_header() to get a column name\n",
    "# Append the Non-empty column name (`if name is not None and len(name) > 0`) into a list called column_names\n",
    "# Define the extract_column_from_header function\n",
    "th_elements = first_launch_table.find_all('th')\n",
    "\n",
    "# Iterate each th element and extract column name\n",
    "for th in th_elements:\n",
    "    name = extract_column_from_header(th)\n",
    "    if name is not None and len(name) > 0:\n",
    "        column_names.append(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the extracted column names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Flight No.', 'Date and time ( )', 'Launch site', 'Payload', 'Payload mass', 'Orbit', 'Customer', 'Launch outcome']\n"
     ]
    }
   ],
   "source": [
    "print(column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 3: Create a data frame by parsing the launch HTML tables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create an empty dictionary with keys from the extracted column names in the previous task. Later, this dictionary will be converted into a Pandas dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "launch_dict= dict.fromkeys(column_names)\n",
    "\n",
    "# Remove an irrelvant column\n",
    "del launch_dict['Date and time ( )']\n",
    "\n",
    "# Let's initial the launch_dict with each value to be an empty list\n",
    "launch_dict['Flight No.'] = []\n",
    "launch_dict['Launch site'] = []\n",
    "launch_dict['Payload'] = []\n",
    "launch_dict['Payload mass'] = []\n",
    "launch_dict['Orbit'] = []\n",
    "launch_dict['Customer'] = []\n",
    "launch_dict['Launch outcome'] = []\n",
    "# Added some new columns\n",
    "launch_dict['Version Booster']=[]\n",
    "launch_dict['Booster landing']=[]\n",
    "launch_dict['Date']=[]\n",
    "launch_dict['Time']=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Flight No.': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121], 'Launch site': ['CCAFS', 'CCAFS', 'CCAFS', 'CCAFS', 'CCAFS', 'VAFB', 'CCAFS', 'CCAFS', 'Cape Canaveral', 'Cape Canaveral', 'Cape Canaveral', 'Cape Canaveral', 'Cape Canaveral', 'Cape Canaveral', 'Cape Canaveral', 'Cape Canaveral', 'Cape Canaveral', 'Cape Canaveral', 'Cape Canaveral', 'Cape Canaveral', 'VAFB', 'Cape Canaveral', 'Cape Canaveral', 'Cape Canaveral', 'Cape Canaveral', 'Cape Canaveral', 'Cape Canaveral', 'Cape Canaveral', 'VAFB', 'KSC', 'KSC', 'KSC', 'KSC', 'KSC', 'KSC', 'KSC', 'VAFB', 'KSC', 'KSC', 'VAFB', 'KSC', 'VAFB', 'KSC', 'KSC', 'Cape Canaveral', 'VAFB', 'CCAFS', 'CCAFS', 'VAFB', 'CCAFS', 'VAFB', 'CCAFS', 'CCAFS', 'KSC', 'VAFB', 'CCAFS', 'CCAFS', 'CCAFS', 'VAFB', 'CCAFS', 'CCAFS', 'VAFB', 'KSC', 'VAFB', 'CCAFS', 'CCAFS', 'VAFB', 'CCAFS', 'KSC', 'CCAFS', 'CCAFS', 'VAFB', 'CCAFS', 'CCAFS', 'CCAFS', 'CCAFS', 'CCAFS', 'CCAFS', 'KSC', 'CCAFS', 'CCAFS', 'CCAFS', 'KSC', 'KSC', 'KSC', 'CCAFS', 'CCAFS', 'CCAFS', 'CCAFS', 'KSC', 'CCAFS', 'CCAFS', 'KSC', 'KSC', 'KSC', 'CCAFS', 'CCAFS', 'KSC', 'VAFB', 'CCAFS', 'KSC', 'CCSFS', 'KSC', 'CCSFS', 'KSC', 'CCSFS', 'CCSFS', 'CCSFS', 'KSC', 'CCSFS', 'KSC', 'CCSFS', 'CCSFS', 'KSC', 'CCSFS', 'KSC', 'CCSFS', 'KSC', 'CCSFS', 'KSC', 'CCSFS'], 'Payload': ['Dragon Spacecraft Qualification Unit', 'Dragon', 'Dragon', 'SpaceX CRS-1', 'SpaceX CRS-2', 'CASSIOPE', 'SES-8', 'Thaicom 6', 'SpaceX CRS-3', 'Orbcomm-OG2', 'AsiaSat 8', 'AsiaSat 6', 'SpaceX CRS-4', 'SpaceX CRS-5', 'DSCOVR', 'ABS-3A', 'SpaceX CRS-6', 'TürkmenÄlem 52°E / MonacoSAT', 'SpaceX CRS-7', 'Orbcomm-OG2', 'Jason-3', 'SES-9', 'SpaceX CRS-8', 'JCSAT-14', 'Thaicom 8', 'ABS-2A', 'SpaceX CRS-9', 'JCSAT-16', 'Iridium NEXT', 'SpaceX CRS-10', 'EchoStar 23', 'SES-10', 'NROL-76', 'Inmarsat-5 F4', 'SpaceX CRS-11', 'BulgariaSat-1', 'Iridium NEXT', 'Intelsat 35e', 'SpaceX CRS-12', 'Formosat-5', 'Boeing X-37B', 'Iridium NEXT', 'SES-11', 'Koreasat 5A', 'SpaceX CRS-13', 'Iridium NEXT', 'Zuma', 'GovSat-1', 'Paz', 'Hispasat 30W-6', 'Iridium NEXT', 'SpaceX CRS-14', 'Transiting Exoplanet Survey Satellite', 'Bangabandhu-1', 'Iridium NEXT', 'SES-12', 'SpaceX CRS-15', 'Telstar 19V', 'Iridium NEXT', 'Merah Putih', 'Telstar 18V', 'SAOCOM 1A', \"Es'hail 2\", 'SSO-A', 'SpaceX CRS-16', 'GPS III', 'Iridium NEXT', 'Nusantara Satu', 'Crew Dragon Demo-1', 'SpaceX CRS-17', 'Starlink', 'RADARSAT Constellation', 'SpaceX CRS-18', 'AMOS-17', 'Starlink', 'SpaceX CRS-19', 'JCSat-18', 'Starlink', 'Crew Dragon in-flight abort test', 'Starlink', 'Starlink', 'SpaceX CRS-20', 'Starlink', 'Starlink', 'Crew Dragon Demo-2', 'Starlink', 'Starlink', 'GPS III', 'ANASIS-II', 'Starlink', 'Starlink', 'SAOCOM 1B', 'Starlink', 'Starlink', 'Starlink', 'Starlink', 'GPS III', 'Crew-1', 'Sentinel-6 Michael Freilich (Jason-CS A)', 'Starlink', 'SpaceX CRS-21', 'SXM-7', 'NROL-108', 'Türksat 5A', 'Starlink', 'Transporter-1', 'Starlink', 'Starlink', 'Starlink', 'Starlink', 'Starlink', 'Starlink', 'Starlink', 'Crew-2', 'Starlink', 'Starlink', 'Starlink', 'Starlink', 'Starlink', 'SpaceX CRS-22', 'SXM-8'], 'Payload mass': [None, None, '525 kg', '4,700 kg', '4,877 kg', '500 kg', '3,170 kg', '3,325 kg', '2,296 kg', '1,316 kg', '4,535 kg', '4,428 kg', '2,216 kg', '2,395 kg', '570 kg', '4,159 kg', '1,898 kg', '4,707 kg', '1,952 kg', '2,034 kg', '553 kg', '5,271 kg', '3,136 kg', '4,696 kg', '3,100 kg', '3,600 kg', '2,257 kg', '4,600 kg', '9,600 kg', '2,490 kg', '5,600 kg', '5,300 kg', 'C', '6,070 kg', '2,708 kg', '3,669 kg', '9,600 kg', '6,761 kg', '3,310 kg', '475 kg', '4,990 kg', '9,600 kg', '5,200 kg', '3,500 kg', '2,205 kg', '9,600 kg', 'C', '4,230 kg', '2,150 kg', '6,092 kg', '9,600 kg', '2,647 kg', '362 kg', '3,600 kg', '6,460 kg', '5,384 kg', '2,697 kg', '7,075 kg', '9,600 kg', '5,800 kg', '7,060 kg', '3,000 kg', '5,300 kg', '~4,000 kg', '2,500 kg', '4,400 kg', '9,600 kg', '4,850 kg', '12,055 kg', '2,495 kg', '13,620 kg', '4,200 kg', '2,268 kg', '6,500 kg', '15,600 kg', '2,617 kg', '6,956 kg', '15,600 kg', '12,050 kg', '15,600 kg', '15,600 kg', '1,977 kg', '15,600 kg', '15,600 kg', '12,530 kg', '15,600 kg', '15,410 kg', '4,311 kg', '5,000–6,000 kg', '14,932 kg', '~15,440 kg', '3,130 kg', '15,600 kg', '15,600 kg', '15,600 kg', '15,600 kg', '4,311 kg', '~12,500 kg', '1,192 kg', '15,600 kg', '2,972 kg', '7,000 kg', 'C', '3,500 kg', '15,600 kg', '~5,000 kg', '15,600 kg', '15,600 kg', '15,600 kg', '15,600 kg', '15,600 kg', '15,600 kg', '15,600 kg', '~13,000 kg', '15,600 kg', '15,600 kg', '15,600 kg', '~14,000 kg', '15,600 kg', '3,328 kg', '7,000 kg'], 'Orbit': ['LEO', 'LEO', 'LEO', 'LEO', 'LEO', 'Polar orbit', 'GTO', 'GTO', 'LEO', 'LEO', 'GTO', 'GTO', 'LEO', 'LEO', 'HEO', 'GTO', 'LEO', 'GTO', 'LEO', 'LEO', 'LEO', 'GTO', 'LEO', 'GTO', 'GTO', 'GTO', 'LEO', 'GTO', 'Polar', 'LEO', 'GTO', 'GTO', 'LEO', 'GTO', 'LEO', 'GTO', 'LEO', 'GTO', 'LEO', 'SSO', 'LEO', 'Polar', 'GTO', 'GTO', 'LEO', 'Polar', 'LEO', 'GTO', 'SSO', 'GTO', 'Polar', 'LEO', 'HEO', 'GTO', 'Polar', 'GTO', 'LEO', 'GTO', 'Polar', 'GTO', 'GTO', 'SSO', 'GTO', 'SSO', 'LEO', 'MEO', 'Polar', 'GTO', 'LEO', 'LEO', 'LEO', 'SSO', 'LEO', 'GTO', 'LEO', 'LEO', 'GTO', 'LEO', 'Sub-orbital', 'LEO', 'LEO', 'LEO', 'LEO', 'LEO', 'LEO', 'LEO', 'LEO', 'MEO', 'GTO', 'LEO', 'LEO', 'SSO', 'LEO', 'LEO', 'LEO', 'LEO', 'MEO', 'LEO', 'LEO', 'LEO', 'LEO', 'GTO', 'LEO', 'GTO', 'LEO', 'SSO', 'LEO', 'LEO', 'LEO', 'LEO', 'LEO', 'LEO', 'LEO', 'LEO', 'LEO', 'LEO', 'LEO', 'LEO', 'LEO', 'LEO', 'GTO'], 'Customer': ['SpaceX', 'NASA', 'NASA', 'NASA', 'NASA', 'MDA', 'SES', 'Thaicom', 'NASA', 'Orbcomm', 'AsiaSat', 'AsiaSat', 'NASA', 'NASA', 'USAF', 'ABS', 'NASA', None, 'NASA', 'Orbcomm', 'NASA', 'SES', 'NASA', 'SKY Perfect JSAT Group', 'Thaicom', 'ABS', 'NASA', 'SKY Perfect JSAT Group', 'Iridium Communications', 'NASA', 'EchoStar', 'SES', 'NRO', 'Inmarsat', 'NASA', 'Bulsatcom', 'Iridium Communications', 'Intelsat', 'NASA', 'NSPO', 'USAF', 'Iridium Communications', 'SES S.A.', 'KT Corporation', 'NASA', 'Iridium Communications', 'Northrop Grumman', 'SES', 'Hisdesat', 'Hispasat', 'Iridium Communications', 'NASA', 'NASA', 'Thales-Alenia', 'Iridium Communications', 'SES', 'NASA', 'Telesat', 'Iridium Communications', 'Telkom Indonesia', 'Telesat', 'CONAE', \"Es'hailSat\", 'Spaceflight Industries', 'NASA', 'USAF', 'Iridium Communications', 'PSN', 'NASA', 'NASA', 'SpaceX', 'Canadian Space Agency', 'NASA', 'Spacecom', 'SpaceX', 'NASA', 'Sky Perfect JSAT', 'SpaceX', 'NASA', 'SpaceX', 'SpaceX', 'NASA', 'SpaceX', 'SpaceX', 'NASA', 'SpaceX', 'SpaceX', 'U.S. Space Force', 'Republic of Korea Army', 'SpaceX', 'SpaceX', 'CONAE', 'SpaceX', 'SpaceX', 'SpaceX', 'SpaceX', 'USSF', 'NASA', 'NASA', 'SpaceX', 'NASA', 'Sirius XM', 'NRO', 'Türksat', 'SpaceX', 'Various', 'SpaceX', 'SpaceX', 'SpaceX', 'SpaceX', 'SpaceX', 'SpaceX', 'SpaceX', 'NASA', 'SpaceX', 'SpaceX', 'SpaceX', 'SpaceX', 'SpaceX', 'NASA', 'Sirius XM'], 'Launch outcome': ['Success\\n', 'Success', 'Success', 'Success\\n', 'Success\\n', 'Success', 'Success', 'Success', 'Success\\n', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Failure', 'Success\\n', 'Success\\n', 'Success\\n', 'Success', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success\\n', 'Success', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n'], 'Version Booster': ['F9 v1.07B0003.18', 'F9 v1.07B0004.18', 'F9 v1.07B0005.18', 'F9 v1.07B0006.18', 'F9 v1.07B0007.18', 'F9 v1.17B10038', 'F9 v1.1', 'F9 v1.1', 'F9 v1.1', 'F9 v1.1', 'F9 v1.1', 'F9 v1.1[', 'F9 v1.1[', 'F9 v1.1[', 'F9 v1.1[', 'F9 v1.1[', 'F9 v1.1[', 'F9 v1.1[', 'F9 v1.1[', 'F9 FT[', 'F9 v1.1[', 'F9 FT[', 'F9 FT[', 'F9 FT[', 'F9 FT[', 'F9 FT[', 'F9 FT[', 'F9 FT[', 'F9 FT[', 'F9 FT[', 'F9 FT[', 'F9 FT♺[', 'F9 FT[', 'F9 FT[', 'F9 FT[', 'F9 FTB1029.2195', 'F9 FT[', 'F9 FT[', 'F9 B4[', 'F9 FT[', 'F9 B4[', 'F9 B4[', 'F9 FTB1031.2220', 'F9 B4[', 'F9 FTB1035.2227', 'F9 FTB1036.2227', 'F9 B4[', 'F9 FTB1032.2245', 'F9 FTB1038.2268', 'F9 B4[', 'F9 B4B1041.2268', 'F9 B4B1039.2292', 'F9 B4[', 'F9 B5311B1046.1268', 'F9 B4B1043.2322', 'F9 B4B1040.2268', 'F9 B4B1045.2336', 'F9 B5', 'F9 B5349B1048[', 'F9 B5B1046.2354', 'F9 B5[', 'F9 B5B1048.2364', 'F9 B5B1047.2268', 'F9 B5B1046.3268', 'F9 B5[', 'F9 B5[', 'F9 B5B1049.2397', 'F9 B5B1048.3399', 'F9 B5[]413', 'F9 B5[', 'F9 B5B1049.3434', 'F9 B5B1051.2420', 'F9 B5B1056.2465', 'F9 B5B1047.3472', 'F9 B5', 'F9 B5[', 'F9 B5B1056.3482', 'F9 B5', 'F9 B5', 'F9 B5', 'F9 B5', 'F9 B5', 'F9 B5', 'F9 B5', 'F9 B5[', 'F9 B5', 'F9 B5', 'F9 B5', 'F9 B5B1058.2544', 'F9 B5', 'F9 B5B1049.6544', 'F9 B5', 'F9 B5B1060.2563', 'F9 B5B1058.3565', 'F9 B5B1051.6568', 'F9 B5', 'F9 B5', 'F9 B5[', 'F9 B5', 'F9 B5 ♺[', 'F9 B5 ♺[', 'F9 B5 ♺', 'F9 B5 ♺', 'F9 B5', 'F9 B5B1051.8609', 'F9 B5B1058.5613', 'F9 B5 ♺[', 'F9 B5 ♺', 'F9 B5 ♺[', 'F9 B5 ♺[', 'F9 B5 ♺', 'F9 B5B1060.6643', 'F9 B5 ♺', 'F9 B5B1061.2647', 'F9 B5B1060.7652', 'F9 B5B1049.9655', 'F9 B5B1051.10657', 'F9 B5B1058.8660', 'F9 B5B1063.2665', 'F9 B5B1067.1668', 'F9 B5'], 'Booster landing': ['Failure', 'Failure', 'No attempt\\n', 'No attempt', 'No attempt\\n', 'Uncontrolled', 'No attempt', 'No attempt', 'Controlled', 'Controlled', 'No attempt', 'No attempt\\n', 'Uncontrolled', 'Failure ', 'Controlled', 'No attempt', 'Failure', 'No attempt', 'Precluded', 'Success', 'Failure', 'Failure', 'Success', 'Success', 'Success', 'Failure', 'Success', 'Success', 'Success', 'Success', 'No attempt', 'Success', 'Success', 'No attempt', 'Success', 'Success', 'Success', 'No attempt', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Controlled', 'Success', 'Controlled', 'No attempt', 'No attempt', 'No attempt', 'No attempt', 'Success', 'Success', 'No attempt', 'No attempt', 'No attempt', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Failure', 'No attempt', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'No attempt', 'Success', 'Success', 'Success', 'Success', 'No attempt\\n', 'Success', 'Failure', 'Success', 'Failure', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Failure', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success'], 'Date': ['6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021', '6 June 2021'], 'Time': ['04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26', '04:26']}\n"
     ]
    }
   ],
   "source": [
    "# Find all tables with the specific class\n",
    "html_tables = soup.find_all('table', class_='wikitable plainrowheaders collapsible')\n",
    "\n",
    "# Loop through each table and extract data\n",
    "extracted_row = 0\n",
    "for table in html_tables:\n",
    "    for row in table.find_all('tr')[1:]:  # Skip the header row\n",
    "        if row.th:\n",
    "            if row.th.string:\n",
    "                flight_number=row.th.string.strip()\n",
    "                flag=flight_number.isdigit()\n",
    "        else:\n",
    "            flag=False\n",
    "            \n",
    "        cells = row.find_all('td')\n",
    "        \n",
    "        if flag:\n",
    "            extracted_row += 1\n",
    "            launch_dict['Flight No.'].append(extracted_row)\n",
    "            \n",
    "            # Booster version\n",
    "            bv=booster_version(cells[1])\n",
    "            if not(bv):\n",
    "                bv=cells[1].a.string\n",
    "            launch_dict['Version Booster'].append(bv if isinstance(bv, str) else None)   \n",
    "            \n",
    "            # Launch Site\n",
    "            launch_site = cells[2].a.string\n",
    "            launch_dict['Launch site'].append(launch_site if isinstance(launch_site, str) else None)   \n",
    "            \n",
    "            # Payload\n",
    "            payload = cells[3].a.string\n",
    "            launch_dict['Payload'].append(payload if isinstance(payload, str) else None)   \n",
    "            \n",
    "            # Payload Mass\n",
    "            payload_mass = get_mass(cells[4])\n",
    "            launch_dict['Payload mass'].append(payload_mass if isinstance(payload_mass, str) else None)   \n",
    "            \n",
    "            # Orbit\n",
    "            orbit = cells[5].a.string if cells[5].a else cells[5].get_text(strip=True)\n",
    "            launch_dict['Orbit'].append(orbit if isinstance(orbit, str) else None)            \n",
    "            \n",
    "            # Customer\n",
    "            customer = cells[6].a.string if cells[6].a else cells[6].get_text(strip=True) \n",
    "            launch_dict['Customer'].append(customer if isinstance(customer, str) else None)            \n",
    "            #print(customer)\n",
    "            \n",
    "            # Launch outcome\n",
    "            launch_outcome = list(cells[7].strings)[0]\n",
    "            launch_dict['Launch outcome'].append(launch_outcome if isinstance(launch_outcome, str) else None)            \n",
    "            #print(launch_outcome)\n",
    "            \n",
    "            # Booster landing\n",
    "            booster_landing = landing_status(cells[8])\n",
    "            launch_dict['Booster landing'].append(booster_landing if isinstance(booster_landing, str) else None)            \n",
    "\n",
    "            # Get Date and Time\n",
    "            datetimelist = cells[0]\n",
    "            # Date value\n",
    "            date = datatimelist[0].strip(',')\n",
    "            launch_dict['Date'].append(date)  \n",
    "\n",
    "            # Time value\n",
    "            time = datatimelist[1]\n",
    "            launch_dict['Time'].append(time)  \n",
    "            \n",
    "\n",
    "# Print the launch_dict to verify the result\n",
    "print(launch_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we just need to fill up the `launch_dict` with launch records extracted from table rows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually, HTML tables in Wiki pages are likely to contain unexpected annotations and other types of noises, such as reference links `B0004.1[8]`, missing values `N/A [e]`, inconsistent formatting, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simplify the parsing process, we have provided an incomplete code snippet below to help you to fill up the `launch_dict`. Please complete the following code snippet with TODOs or you can choose to write your own logic to parse all launch tables:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you have fill in the parsed launch record values into `launch_dict`, you can create a dataframe from it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.DataFrame({ key:pd.Series(value) for key, value in launch_dict.items() })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now export it to a <b>CSV</b> for the next section, but to make the answers consistent and in case you have difficulties finishing this lab. \n",
    "\n",
    "Following labs will be using a provided dataset to make each lab independent. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>df.to_csv('spacex_web_scraped.csv', index=False)</code>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('spacex_web_scraped.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.linkedin.com/in/yan-luo-96288783/\">Yan Luo</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.linkedin.com/in/nayefaboutayoun/\">Nayef Abou Tayoun</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--\n",
    "## Change Log\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--\n",
    "| Date (YYYY-MM-DD) | Version | Changed By | Change Description      |\n",
    "| ----------------- | ------- | ---------- | ----------------------- |\n",
    "| 2021-06-09        | 1.0     | Yan Luo    | Tasks updates           |\n",
    "| 2020-11-10        | 1.0     | Nayef      | Created the initial version |\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © 2021 IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "prev_pub_hash": "64f1b0aac408997185c47caba18730e0028b75e7934a0e5bf0ae73c5cb7ba677"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
